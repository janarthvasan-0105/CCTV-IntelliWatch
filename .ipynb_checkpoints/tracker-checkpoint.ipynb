{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8e17e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import datetime\n",
    "from ultralytics import YOLO\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "import torchreid\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from scipy.spatial.distance import cosine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72eadf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_model = YOLO(\"yolov8n.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d15bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "osnet_model = torchreid.models.build_model(\n",
    "    name='osnet_x0_25', \n",
    "    num_classes=1000, \n",
    "    pretrained=True\n",
    ")\n",
    "osnet_model.eval() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f8ab38",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((256, 128)), \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391195bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker = DeepSort(\n",
    "    max_age=200, \n",
    "    n_init=5, \n",
    "    nms_max_overlap=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0a9a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIDENCE_THRESHOLD = 0.5\n",
    "NMS_THRESHOLD = 0.3\n",
    "GREEN = (0, 255, 0)\n",
    "WHITE = (255, 255, 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d16068f",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_cap = cv2.VideoCapture(\"test_videos/How+to+Do+Play+Therapy+_+Building+a+Growth+Mindset+Role+Play.mp4\")\n",
    "\n",
    "frame_width = int(video_cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(video_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = video_cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "out = cv2.VideoWriter(\"output_person_tracking_7.mp4\", cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n",
    "\n",
    "track_embedding_history = {}\n",
    "last_seen = {}\n",
    "REIDENTIFY_DELAY_FRAMES = 30\n",
    "\n",
    "while video_cap.isOpened():\n",
    "    ret, frame = video_cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    start_time = datetime.datetime.now()\n",
    "\n",
    "    \n",
    "    results = yolo_model(frame)[0]\n",
    "    detections = []\n",
    "    embeddings = []\n",
    "    for data in results.boxes.data.tolist():\n",
    "        confidence = data[4]\n",
    "        if float(confidence) >= CONFIDENCE_THRESHOLD:\n",
    "            xmin, ymin, xmax, ymax = int(data[0]), int(data[1]), int(data[2]), int(data[3])\n",
    "            class_id = int(data[5])\n",
    "            # Only track persons \n",
    "            if class_id == 0:\n",
    "                bbox = [xmin, ymin, xmax - xmin, ymax - ymin]\n",
    "                detections.append([bbox, confidence, class_id])\n",
    "                \n",
    "                person_img = frame[ymin:ymax, xmin:xmax]\n",
    "                if person_img.size > 0:\n",
    "                    person_img = transform(person_img).unsqueeze(0)\n",
    "                    with torch.no_grad():\n",
    "                        embedding = osnet_model(person_img)\n",
    "                    embeddings.append(embedding.squeeze(0).cpu().numpy())\n",
    "\n",
    "    tracks = tracker.update_tracks(detections, frame=frame)\n",
    "\n",
    "    for i, track in enumerate(tracks):\n",
    "        if not track.is_confirmed() or track.det_class != 0:  \n",
    "            continue\n",
    "\n",
    "        track_id = track.track_id\n",
    "        ltrb = track.to_ltrb()  \n",
    "        xmin, ymin, xmax, ymax = int(ltrb[0]), int(ltrb[1]), int(ltrb[2]), int(ltrb[3])\n",
    "\n",
    "        if i < len(embeddings): \n",
    "            current_embedding = embeddings[i]\n",
    "            if track_id not in track_embedding_history:\n",
    "                if track_id in last_seen and (video_cap.get(cv2.CAP_PROP_POS_FRAMES) - last_seen[track_id]) < REIDENTIFY_DELAY_FRAMES:\n",
    "                    continue  \n",
    "                \n",
    "                for past_id, past_embedding in track_embedding_history.items():\n",
    "                    distance = cosine(current_embedding, past_embedding)\n",
    "                    if distance < 0.25:\n",
    "                        track_id = past_id\n",
    "                        break\n",
    "\n",
    "            track_embedding_history[track_id] = current_embedding\n",
    "            last_seen[track_id] = video_cap.get(cv2.CAP_PROP_POS_FRAMES)\n",
    "\n",
    "        cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), GREEN, 2)\n",
    "        cv2.putText(frame, f\"ID: {track_id}\", (xmin, ymin - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, WHITE, 2)\n",
    "        \n",
    "    # Calculate and display FPS\n",
    "    end_time = datetime.datetime.now()\n",
    "    fps_text = f\"FPS: {1 / (end_time - start_time).total_seconds():.2f}\"\n",
    "    cv2.putText(frame, fps_text, (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "    cv2.imshow(\"Person Detection & Tracking (OSNet)\", frame)\n",
    "    out.write(frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "video_cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040c1922",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (NeuroMouse)",
   "language": "python",
   "name": "neuromouse"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
